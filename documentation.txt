1- utils/credentials.json for google connection/authentication
2- utils/config.py for adjusting configurations like sandbox api path, google drive folder id and columns to exclude
3- new links will save in utils/links.json
4- we are going to deploy app in virtual machine/server (digital ocean)
    user: ssh root@161.35.158.228
    pass: FPt+Fny+iT%mM9F
    steps:
        1- install anaconda
            -> cd /tmp
            -> curl -O https://repo.anaconda.com/archive/Anaconda3-2019.03-Linux-x86_64.sh
            -> sha256sum Anaconda3-2019.03-Linux-x86_64.sh
            -> bash Anaconda3-2019.03-Linux-x86_64.sh
            -> yes, enter
            -> cd
            -> source anaconda3/bin/activate
            -> conda config --set auto_activate_base true
        2- create anaconda environment for django app
            -> conda create -n bigbuy_env1 python=3
        3- activate environment:
            -> conda activate bigbuy_env1
        4- install requirements for django app
            -> cd /root/bigbuycsvs
            -> pip install -r requirements.txt
        5- install npm
            -> sudo apt update
            -> sudo apt install npm
        6- install pm2 using npm
            -> npm install pm2 -g
        7- allow port to communicate
            -> sudo ufw allow 8000
        8- run django app
            -> python manage.py runserver 0.0.0.0:8000
        9- run django app on pm2 server
            -> pm2 start "cd /root/bigbuycsvs/ && /root/anaconda3/envs/bigbuy_env1/bin/python manage.py runserver 0.0.0.0:8000"
        10- now schedule the csv processor script
            - for that we will use crontab, which is stable and efficient
            -> crontab -e
            -> paste the below cammand and save the cronjob
                =>> */30 */1 * * * cd /root/bigbuycsvs/ && /root/anaconda3/envs/bigbuy_env1/bin/python utils/main.py
                => it means its scheduled after every 1 hour and 30 minutes, you can change it anytime by just changing the values and saving it




